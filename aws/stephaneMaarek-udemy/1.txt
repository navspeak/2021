EC2, IAM basics,
        Draw diagram: https://aws.amazon.com/architecture/icons/ (draw.io)
        1. IAM - global service - all region
        2. https://aws.amazon.com/about-aws/global-infrastructure/
        3. Reboot - When you perform a reboot, the same virtual machine instance is rebooted.
        The original virtual machine instance that was provisioned to you is never returned back to Amazon.
        The private & public IP address will not change on Reboot.  (Stop and Restart will change )
        ==
        Read EC2 instance types: On demand,Reserved (scheduled/convertible), spot, spot fleet, dedicated host(byol) & dedicated instance - page 50
        Spot block for 1-6 almost guaranteed | Read Spot fleet - lowestPrice, diversified, capacityOptimized
        AMI - specific to region. Some may be malware. Lives on S3. Read about AMI with billingProduct
        PlacementGroup: Cluster - Same Rack & AZ - Low Latency (big data job that need to complete fast) | Spread - all EC2 on diff hardware
        spread across AZ (7 instance per AZ) | partition - same AZ - upto 7 partition w/ 100 of EC2 - Hadoop, Cassandra
        ENI - lives in a subnet, bound to AZ (what is Elastic Fabric Adapter)
        ==
        https://aws.amazon.com/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/

        A very important consequence of this new model (and one took me a little while to fully understand) is that the idea of
        launching an EC2 instance on a particular VPC subnet is effectively obsolete.
         A single EC2 instance can now be attached to two ENIs, each one on a distinct subnet.
         The ENI (not the instance) is now associated with a subnet.
        =
        There is a vCPU-based On-Demand Instance limit per region which is why subsequent requests failed.
        Just submit the limit increase form to AWS and retry the failed requests once approved.
        https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html
        -  By default, when you create an EC2 account with Amazon,
           your account is limited to a maximum of 20 instances per EC2 region with two default High I/O Instances (hi1. 4xlarge) (not availability zone).
LB
    CLB - Cross-Zone LB - disabled by default, no charges for inter AZ data if enabled. Layer 4 + 7
    ALB : Cross-Zone LB  always on, no charges for inter AZ data. read Target group. Microservice use case). Layer 7 only
          Target Group : EC2, Lambda or IP
    NLB : Cross-Zone LB dDisabled by default. Not free. Enable - u pay. Has fixed IP per subnet/AZ (ALB/CLB has static hostname). Layer 4 only
          The hosts in Target group see the traffic coming from outside not from NLB. So in the SG of EC2 instance u'll have
          to enable 80 from everywhere unlike ALB and CLB
          AWS PrivateLink (VPC Endpoint Servces require NLB at Service VPC level)
    GLB - New
    --
    Stickiness - in CLB at LB level configuration otherwise at Target group level (with duration that stickiness will last)
    cross zone loadbalancing - enabled at Target group level.
    --
    ASG -  Launch config (old)/ template (new) .Scale in pr out w/Cloud Watch - Target Tracking Policy (CPU % etc) or Step or Simple Scaling (when alarm is reached) or Scheduled actions
        - Lifecycle hooks
    - ipv6 not supported by CLB
    - ALB Target group must use private ip
    - X-Forwarded-For-XXX headers. True client IP not seen
    =================

    NLB: less latency (100 ms cf ALB 400ms)
    NLB: one static IP per AZ (CLB & ALB had static host name), and supports assigning Elastic IP (helpful for whitelisting specific IP)
    https://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-register-targets.html#target-security-groups
    NLB - no security group attached. So instances attached to NLB's instance group see traffic coming from outside not from NLB.
    So we need to open port from outside instead of NLB SG which doesn't exist.
    Inbound custom TCP 80 (not http) from 0.0.0.0/0.
    For bastion hosr
    ===
    ACM - AWS Certificate Manager
    Clients can use SNI to specify the hostname they
    reach. Supported for ALB, NLB & CloudFront. (not clb)

    Connection Draining for CLB or Deregistration Delay for NLB and ALB. (cf CoolDown period for ASG)
    It is the time to complete "in-flight requests" while the instance is de-registering or unhealthy.
    At that time it stops sending new request to the instance which is de-registering.
    De-registering delay can be configured to a value b/w 1 to 3600 seconds. Default is 300 secs.Can be disabled by setting it to be 0.
    This is important to set in accordance with a round trip time the EC2 instance takes so that an existing request completes.
=====================================================
EBS vs Instance Store vs EFS
    EBS or Instance store
    - lsblk
    - sudo file -s /dev/xvdb
    /dev/xvdb: data => means no filesystem on the device
    - sudo mkfs -t ext4 /dev/xvdb
    (format the fs)
    - sudo mkdir data
    - sudo mount /dev/xvdb /data (mount)
    - lblk and see xvdb is mounted to /data
    - cd /data && touch hello.txt
    https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html
    The mount point is not automatically preserved after rebooting your instance.
    To automatically mount this EBS volume after reboot:
    - sudo cp /etc/fstab /etc/fstab.orig
    vi /etc/fstab
    add line
    /dev/xvdb /data ext4 defaults,nofail  0  2
    sudo file -s /dev/xvdb
    (to see if file is formatted)
    sudo unmount /data
    lsblk
    sudo mount -a (remount)
    ==
    EFS (read page 315 - compare with FSx for Windows vs FSx for Lustre)
    ==

    ==
    GP2: 1 GB - 16 TB(burst IOPS to 3000, min 100 & max 16000, 3 iops per GB => depend on size)

    IO1 - 4 GB to 16 TB( for iops > 16000. piops. IOPS can be min 100 to max 64000 (for nitro) / 32000 (others IOPS, but in ratio of ipos:volume :: 50:1)

    ST1 - 125 GB-16 TB Thruput optimized. Straming workload requiring consistent & fast thruput at low price. Datawarehousing, kafka (40 MB/s per TB) Max IOPs = 500 MB. can burst

    SC1 - 125 GB - 16 MB (12 MB/s TB). can burst
    snapsot of unencrypted vol are unenc. So 1st create an encrypted snapshot of unencrypted snapshot and then a vol from that in any region
    - Instance Store
    - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default - region specific
    - EBS - RAID0 - high IOPs (100,000) but not fault tolerant. RAID 1 - hight fault tolerant. Mirroring
    - EFS = multi AZ => mounted File System. Highly available. Only Linux. NFS. Can scale up. (petabyte scale)
           - Standard Tier (frequently accessed) | EFS-IA (lower price to store higher to retrieve)
           - Lifecyle mgmt like S3
           - define SG for each AZ while create EFS. Also for EC2 instance we create another SG which must be allowed in SG of EFS (as NFS)
    ==
RDS, Elasticache - Memcached or redis
        ===
        - page 170
        - https://tutorialsdojo.com/amazon-relational-database-service-amazon-rds/
        - Free Tier: 750 hrs of RDS in a single t2.micro.instance, 20 GB general Purpose SSD, 20GB automated backup storage and any user-initiated DB snapshots
        - storage backed by EBS (gp2 or io1) | managed service, can't ssh into
        Backup are automatically enabled in RDS
        - storage autoscaling (checkbox) => specify maximum storage threshold | MultiAZ diabled in Freetier
        - Daily full backup of database (during the maintenance window)
        - Transaction logs are backed-up by RDS every 5 mins
        - ability to restore to any point in time (from oldest backup to 5 mins ago)
        - 7 days retention (can be increased to 35 days)
        DB snapshots: manually triggered. Retention of backup as long as you want.
        --
        Read Replicas for read scalility - within AZ, cross AZ, cross region | ASYNC replication |Replicas can be promoted to its own DB
                   Application must update connection string to leverage the read replicas |
                   READ replicas used only for SELECT not INSERT, UPDATE etc |
                   ** RDS Read replicas in same region is free. Cross region is charged.

        - Multi AZ for Disaster Recovery - SYNC Replication to standby instance | One DNS name -automatic failover to standby | no manual intervention
           Not used for scaling (i.e. can't read or write to standby instance) | Reboot with Failover option to manulaly failover to a standby replica
        - At rest encryption - defined at launch time AWS KMS -AES256. TDE for Oracle and SQL Server
        - In flight encryption - SSL certificate. Enforce SSL: PostgreSQL: rds.force_ssl=1
        IAM auth for MySQL and Postgres (AWSAuthentication Plugin)
        - https://www.youtube.com/watch?v=o4Sf5Z6E2lk
        - CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance,
          and Enhanced Monitoring gathers its metrics from an agent on the instance.
        - CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance,
        and Enhanced Monitoring gathers its metrics from an agent on the instance.
        - When creating a read replica, there are a few things to consider.
         First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0.

        Q) Can Read replicas be used as Multi AZ standby -> Ans) YES
        --
        aurora - reader end point and writer end point. auto scaling
        - 5x perf over MySQL, 3x over postgres
        - Aurora groyw in increments of 10 GB upto 64 TB. 15 Replicas vs 5 for mysql (faster replication 10 ms lag)
        - HA native. Failover automatic
        --
        elasticache - memcached (sharding i.e. multi node partioning. Not HA. Multi threaded, not persistent) vs
         - redis (AOF persistence, auto failover. Persistence. Replicas, MultiAZ) - both do not support iam authn
         - Redis Auth Token when u enable encryption in transit
         - Architect Leaderboad - Redis Sorted Set
        https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/RedisAOF.html
        - All caches in ElasticCache support SSL in flight encryption but do not support IAM authn.
         - IAM policies on ElastiCache are only used for AWS API level security
        - Redis AUTH: password/token extra security above security group
        - Memcached - SASL based authn
        - Pattern: Lazy loading (all data cached, can become stale),
          write thru (adds or updates data in cache when written to a db - no stale data), session store (store temp session data in a cache using TTL feature)

Route 53 (global service): DNS + Domain Registrar
===
    - https://tutorialsdojo.com/amazon-route-53/
    Route 66 + Port 53 = Historic cross-country american highway + port where DNS server requests are addressed
    A:  hostname to IPV4,
    AAAA: hostname to IPV6
    cname: hostname to hostname,
    alias: hostname to aws resource
    A Pointer (PTR) record resolves an IP address to a fully-qualified domain name (FQDN) as an opposite to what A record does. PTR records are also called Reverse DNS records. 'PTR record' cannot be used to map one domain name to another
    ---
   Route53 can use - public domain names that you can buy. Private domain names that can be resolved by your VPCs
   - can be used for LB, Heath check,
   - Routing policy: simple, failover, geolocation, latency, weighted, multi value
   - pay $0.50 per month per hosted zone.
   - is a global service
   - nslookup or dig
   - Read Geoproximity for bias in Route 53 vs Geolocation for affinity https://medium.com/awesome-cloud/aws-amazon-route-53-routing-policies-overview-285cee2d4d3b
   - EC2 lab:
   - DNS Record TTL - web browser will cache A record for TTL (High TTL 24 hrs, less traffic on DNS, possible outdated records)
                 - is mandatory
  - CNAME: hostname or AWS Resource like ELB exposes AWS hostname which you want to map to ur DNS name.
        Works only for non root domain (eg: something.mydomaol.com => lb1-1234.us-east-2.elb.amazonaws.com). Paid
  - Alias: Points only to a hostname to an AWS Resource. Works for root + non root domain (aka mydomain.com).
       Free of charge. Native health check
  Routing
    - Simple Routing w/ 2 addresses (can enter together in one box): browser randomly choses one
       (Route53 returns all A record ip. Dig will show both IPs as answer). No health check
    - Weighted Routing Policy: note dig will not be aware that there are multiple ips (dig will get 1 answer). Health chk
    - Latency Routing Policy
    - Failover Routing-primary must have healthcheck ( Health check - new user gets 50 free)
    - Geolocation - can set default location as catch all for all geo not specified
    - Geoproxity - bias 1-99. Traffic flow
    - Multivalue - browser gets all IPs that are healthy
  Health Checks
    cost (min 0.50 for aws resource. upto 50 free)
    X heath check failed(def 3) => unhealthy | X health check passed => healthy (def 3)
    Default Health Check Interval: 30s (can set to Fast 10s - higher cost)
    About 15 health checkers will check the endpoint health (= one request every 2 sec on avg if  health check int = 30 s)
    Can have HTTP, TCP & HTTPS health checks (no ssl verification)
    can monitor Endpoint, status of another health chk or state of cloudwatch alarm
   Route53 is also a registrar like GoDaddy
    Domain Registar != DNS
    3rdparty Domain => name server point in the hosted zone (NS)
    Q) You have purchased a domain on Godaddy and would like to use it with Route 53.
    What do you need to change to make this work?
    A) Create Public Hosted zone + update NS of 3rd party registrar
    Private hosted zones are meant to be used for internal network queries and are not publicly accessible.
    Public Hosted Zones are meant to be used for people requesting your website through the public internet.
    Finally, NS records must be updated on the 3rd party registrar.
    - In a private hosted zone, you can associate Route 53 health checks only with weighted and failover records.
     - You can use the following routing policies when you create records in a private hosted zone:
      Simple
      Failover
      Multivalue answer
      Weighted
 - Total length of DNS name <= 255 bytes
 - Health check - fast 10 sec - cost (default 30 sec). 15 health checkers (you can see the IP of those machines
   that ping the instances in b/g to determine the health)

===
Architecture discussion
    5 pillars: Costs, performance, reliability, security, operational excellence
    Golden AMI + bootstrap script = quick instantiation of EC2
    Restore from Snapshot = quick inst. for RDS
    Restore from Snapshot for EBS too (disk already formatted and has data)
    Elastic BeanStack
     - Free | Managed service from AWS | Pay for underlying instance, RDS etc (read cloudformation)
===
s3
  - IMP UPDATE: Strongly consistent after PUT: https://aws.amazon.com/s3/consistency/
  - sharing S3 bucket: https://www.youtube.com/watch?v=sfQ8tBuxfRY
                     https://www.youtube.com/watch?v=zcY0sDPzlyc
  - global | max size - 5TB | > 5GB multi part | Metadata (list of text key/value pairs - system or user metadata)
  - Tags (Unicode up to 10) - useful for security / lifecycle | VersionID
  - You choose region while creating S3 bucket but s3 is global
  - You can access a private S3 object when you access from AWS console  (object action > open) but get forbidden when you access using public URL
    - Answer: presigned URL
  - Any file that is not versioned prior to enabling versioning will have version "null".
   Suspending versioning doesnt delete prev versions
  - delete delete marker - undo delete. Delete a version - permanently delete
  - S3 performance => 3500 PUT/COPY/POST/DELETE, 5500 GET/HEAD per prefix per sec.
                   => with 2 prefix 11000 GET requests per sec
  - Multipart upload for 5GB (recommended for 100 MB or above) | S3 Upload performance - Transfer accelerator
  - Byte Range Fetch to download parts of file
  - How to prevent cloudfront front from caching
  - Depending on your Region, your Amazon S3 website endpoints follow one of these two formats. https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteEndpoints.html
        s3-website dash (-) Region ‐ http://bucket-name.s3-website.Region.amazonaws.com
        s3-website dot (.) Region ‐ http://bucket-name.s3-website-Region.amazonaws.com
        These URLs return the default index document that you configure for the website.
  - S3 Event notification - only SQS std
  S3 Encryption -
  https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html
    1. SSE-S3
       AWS manages Keys used for enc. Server side enc of obj. AES256. x-amz-server-side-encryption:AES256
    2. SSE-KMS (You need to call AWS KMS encrypt & decrypt API)
       AWS manages data key but you manage customer master key | obj enc at server side | adv : control + audit trail
       x-amz-server-side-encryption:aws:kms
    3. SSE-C: server side enc using keys managed cust (which AWS discards after enc) | use of HTTPs mandatory |
       possible using CLI only
    4. Client Side Encryption: AWS S3 Encryption lib. Encrypt at client side using the lib b4 sending. Decrypt upon retrieval.
        (can be sym or asym - 256 bits keys)
    The bucket policy allows our users to read/write files in the bucket, yet we were not able to perform a PutObject API call.
    Explicit DENY in an IAM policy will take precedence over a bucket policy permission
   LAB: How to you prevent upload of objects not encrypted SSE-S3 scheme (create bucket policy)
   https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/
   For file level use ACL
   - S3 Website (static Website hosting in bucket policy) - disbale Block Public Access. +
      add bucket policy to allow GET to anyone
    ===
    MFA Delete: Need to enable versioning. Neededed to permanently delete or disable version. Not to enable version
    S3 Access Log - behind the scene go to permissions -
       see under ACL S3 Log delivery Group has permission to Write and Read
    S3 Replication (CRR & SRR)  - bucket can be in different accounts.
    Delete not replicated (marker can be if opted in for). No chaining. Only new Objects replicated
    Pre signed URL: SDK or CLI. Validity --expire-in 3600 sec. Users given a pre-signed URL inherit the permissions of the person who generated the URL
    S3 storage class: stored in glacier, first need to restore
     - Glacier: Bulk retrieval (5-12 hrs), Std (3-5 hrs) and expedited (1-5 mins)
     - Glacier deep archive (48 hrs retrieval)
    s3 select & glacier select: SQL to filter data at server side. Less traffic.(400% fasterm 80% cheaper)
    (for complex, use athena)

        s3 notification:SNS, SQS, lamda function. If two writes are made to a single non versioned obj at same time,
        one event may be lost. To ensure that event notification is sent for every successful write,
        you can enable versioning on your bucket.

        Athena: Serverless service to perform analytics. Charged per query and amount of data scanned
        S3 Lock Policies & Vault Lock: WORM
     S3 Select
     https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html
     Standard to All (none to standard)
     Standard - IA after 3o days
     One-zone to only glacier/Deep Archive
     Intellizent-Tier to all all except Std and Std-IA
     Glacier Deep Archive to None
     ======
     client = boto3.client('s3')
     resp = client.select_object_content(
     Bucket='tdojo-bucket', # Bucket Name.
     Key='s3-select/tutorialsdojofile.csv', # Object Key.
     ExpressionType= 'SQL',
     Expression = "select \"Sample\" from s3object s where s.\"tutorialsdojofile\" in ['A', 'B']"
==
CloudFront:
Origns:
  S3 buckets: For distributing files & caching them at edge | as ingress (to upload filesin S3)
              enhanced security w/CloudFront Origin Access Identity (OAI)
   Custom Origin (HTTP)
        - Application Load Balancer, Ec2 instance, S3 website (must first enable the bucket as static s3 website)
   GeoRestriction : WhiteList / BlackList countries. Uses 3rd party Gei-IP DB

========
CloudFront: (is a CDN - cached at Edge Location)
        - integration w/Shield (DDos)
        - Create s3 bucket - create CloudFront distribution - create OAI -limit s3 bucket to be accessed only using this identity
        - GeoLocation - whitelist or blacklist
        - CloudFront vs S3 CRR - 1 main diff CloudFront caches maybe with TTL = 1 day. S3 CRR - near real time
        - Lab - create CloudFront "distribution" w/ web type of origin (other is RTMP for media) one s3 as origin. Restrict Bucket access.
              In bucket policy u'll see All to Principal : CloudFront:user Origin Access Identity EXSOMEIDXXX (we can edit and deny access from
              any other principal other than OAI) or just make the files in bucket private, so bucket policy will kick in and allow from OAI associated with
              cloudfront.
              - sometimes when u hit cloudfront URL you'll be redirected to S3 URL which is because of DNS propagation delay. It's just temp
        - Read OAI. Read tempor (see OAI.PNG)
        - ClouFront signed URL (per file) vs Cookie (multiple file)
        - CloudFront Field Level encryption
        - Read CloudFront Signed URL vs S3 Pre-Signed URL
        - Read Price Classes
        - Global accelerator: Use AnyCast not unicase (always Oregon region in my case). Anycast IP will send to nearest Edge Location from where it is Private AWS n/w
          (Global Acc - vs Transfer acc - accessed in S3 under properties - will give new s3 URL)
        - lAB : create Endpoint group for each region (assign traffic dial 0 -100) and add endpoints (like ec2 elb etc) in the groups (wight 0-255)
  ===
    - Snowball --> import S3 --> s3 lifecycle policy Amazon Glacier (can't directly import to glacier) - Exabytescale. Transfer more than 10 PB
    - snowball edge - computation
    - AWS Storage Gateway: https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html
        * https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts
        * Bridge on-prem data to say s3 (AWS proprietary stuff). Types: File, Volume and Tape
        - File Gateway
            - S3 to be accessed using NFS/SMB protocol. Bucket access using IAM roles for each file gateway
            - MRU data cached in File Gateway
            - can be mounted on servers
        - Vol Gateway
            - block storage using iSCSI protocol backed by s3.
            - backed by ENS snapshots which help restore on-prem vol
            - Types: Cached vol (1024 TB = 32*32): low latency access to MRU data | Stored Vol (512 TB = 16 * 32): entire dataset is on prem, scheduled backup to s3
        - Tape Gateway
            - VTL, backup with iSCSI
        - File Gatweway - Hardware appliance: (in addition to virtualization capability)
            Use case: Small Data centre with no virtualization. Need to perform daily NFS backup
        ===
        Amazon FSx for Windows (FileServer)
        - similar to what EFS is for Linux (POSIX)
        - Share folders and make accessible to your instance using SMB
        - is multi AZ
        - Amazon FSx for Windows File Server has the features, performance, and compatibility to easily lift and shift enterprise applications to the
         AWS Cloud. It is accessible from Windows, Linux, and macOS compute instances and devices.
          Thousands of compute instances and devices can access a file system concurrently.
        - To migrate file share configurations from your on-premises file system, you must migrate your files first to
         Amazon FSx before migrating your file share configuration.
        - NTFS
       Amazon FSx for Lustre(Linux+ cluster) = large-scale computing. type of parallel distributed FileSysten for large scale
        computing. Machine Learning, HPC (High perf computing)
        - Seamless integration with s3. Can read S3 as file system thru FSx lustre. Can write the output of the computations to S3
        - Not Multi AZ
        (read page 315)

==============
SQL, SNS and Kinesis
===
    SQS = Simple Queue Service - Std or FIFO (name: *.fifo)
      - default retention 4 days (min 1 minute to max 14 days). Less than 246 KB size
      - can be out of order (best effort ordering). Can have duplicates
      - Message visibilty timeout (read about it) - default 30 second - low can cause duplicate. (can be set from 0 - 12 hrs)
        Very high can cause re-processing in case of consumer crsah take long time
      - consumers: Ec2 or lambda. Must call DeleteMessage API after processing
      - Auto Scaling based on Q Length (ApproxNumberOfMessages)
      - Access Policy - IAM or queue owner. In flight encryption enabled by default. Server side encryption AWS KMS.
      - For most standard queues (depending on queue traffic and message backlog), there can be a maximum of approximately
         120,000 inflight messages (received from a queue by a consumer, but not yet deleted from the queue).
      - SQS Temporary Queue Client - For SQS Request Response System. It leverages virtual queue instead of creating & deleting queues
        (correlationID)
      - Delay Queue - Delay between Delivery & Receive - DeliveryDelay = Default 0 to 15 mins
      - Long Polling - 20 seconds
       Q) visibility timeout is set to 30 sec. The consumer processing it realizes he will take longer than that. So in this case the message will reappear in
        the SQS after 30 secs. The consumer will then process it again, causing duplication. Wht can he do to avoid it?
        - call changeMessageVisibility API to get more time
      - Dead Message Queue (this is also SQS):
       With Message Visibilty, you can send back the message to SQS after the consumer fails to consume in a certain time window. This  can cause a loop
       So we can send to DLQ after MaximumReceives exceeds a threshold. Use: debugging
      - Delivery Delays
      - Message timers let you specify an initial invisibility period for a message added to a queue
      https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-timers.html
      FIFO queues don't support timers on individual messages

    FIFO Qs: Exactly-one delivery but limited thruput - Only 330 msg/s without batching (3000 msg/s with batching)
        - Deduplication ID: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagededuplicationid-property.html
    ===============
    SNS : one message to many receivers (pub/sub)
     - Data not persisted. Lost if not consumed
     - Producer -> SNS Topic (100,000) -> Many subscription (10,000,000)
     CloudWatch alarms send notifications to SNS topics. In fact events by S3, cloudformation etc
     SNS + SQS: Fan out
     SNS FIFO
     S3 event = subscriber SNS fanout to SQS
     SNS - message filtering (json policy) on subsription tab (see hands on)
     SNS can NOW send messages to SQS FIFO queues (?)
    ================
    AWS Kinesis => managed alternative to Apache Kafka | streaming data | big data | Clickstream, telemetry
    - Kinesis Streams: low latency streaming ingest at scale (Delivery stream)
            - more shards = more thruput
            - billing per shard provisioned
            - shards . Retention 1 day default to 365 days. Ability to replay. Immutabilty. Data that sharessame partition goes in same shard
            - Producers / KPL : Kinesis Agent (java app to send data to stream), SDK or KPL (Kinesis Prod Lib)
                - Records (partition ket + Data Blob up to 1 MB) - 1 MB/secs or 1000 Msg/sec/shard. On consumer side also seq no.
            - Consumers: AWS KInesis Data Analysys, Firehose, KCL (Kinesis Client Lib)
            - aws kinesis put-record --stream-name test --partition-key user1 --data "signip"
              (also shard iterator to read)
            - One shard provides an ingest capacity of 1MB/second or 1000 records/second and an output capacity of 2MB/second.
    - Kinesis Firehose: (Dilvery stream) - no storage (pg 385)
            - source : Direct PUT or other source OR Kinesis Data Stream
                  - Near Real Time (60 sec latency for non full batches) /32 MB of data at a time
                  - reads record upto 1 MB at a time from Kinesis Data Stream, cloudwatch logs/events, IoT
                  - Transformed by Lambda and batch writes to Dest
            - Dest: load streams into 1) S3, 2) Readshift (via s3), 3) ElasticSearch, 4) Splunk, HTTP endpoint or 3rd part provider 5) Custom HTTP Endpoinyt
            - Failed messafe to S3
    - Kinesis Data Streams (data storage as well 1 day to 365 days. You can raise data retention period to up to 7 days by
      enabling extended data retention or up to 365 by enabling long-term data retention using the console, the CLI or the API call)
      1 shard => 1 MB/s write (2 MB/sec read) or 1000 Data Recods/sec (2000)
    - Kinensis Analytics (to analyze data stream with SQL or Apache Flink) - perform real-time analytics on streams using SQL. Serverless
    - Kinesis Firehose (or Deliver stream) (to ingest data to s3, redshift, elasticSearch, splunk. no storage. Near real time delivery)
    - Kinesis Video Streams (capture, process and store video streams)
    - Amazon MQ = managed Apache Active MQ
==============
    AWS Lambda: can provision up to 3GB of RAM per function. Increasing RAM also improves CPU and Network
    Note: Docker does not run on lambda
    Free tier 1,000,000 AWS lambda req & 400,000 GBs of compute time
    Pay per calls => After 1st 1million reqyuest which is free, u pay 20 cents/1 million request thereafter ($0.0000002 per req)
    pay per duration: in increment of 100 ms
    - 1st 400,000 GB-seconds of compute time per month if Free
       => 400,000 secs if function is 1 GB RAM
      =>3,2000,000 seconds if function is 128 mb RAM (1 GB/8) - Lesser RAM more seconds
    After that $1.00 for 600,000 GB-sec
    AWS attach an IAM role with policy to createLogGroup and write to CloudWatch
    AWS Lambda Limits:
      Execution:
        Memory allocation: 128 MB - 10gb  (64 MB increments)
        Max execution time: 900 secons (15 mins)
        Env Variables (4 KB)
        Disk Capacity in "function container" (in /tmp): 512 MB
        Concurrect executions: 1000 can be increased
      Deployment
        Lambda fn deployment side (compresseded .zip): 50 MB | uncompressed (code + dependencies): 250 MB
        Can use /tmp to load startup files. Env variable 4 KB
    q) You have a Lambda function that will process data for 25 minutes before successfully completing.
     The code is working fine in your machine, but in AWS Lambda it just fails with a "timeout" issue after 3 seconds.
      What should you do? - This won't work in Lambda as maximum timeout is 15 mins'
     Lambda@Edge: deploy Lambda functions alongside your CloudFront CDN
 ===
 DynamoDB
    - https://tutorialsdojo.com/aws-cheat-sheet-amazon-dynamodb/
    - Provides on-demand backup capability as well as enable point-in-time recovery for your DynamoDB tables.
      With point-in-time recovery, you can restore that table to any point in time during the last 35 days. Auto replicated
      to multiAZ. You can create tables that are automatically replicated across two or more AWS Regions, with full support for multi-master writes.
      AWS now specifies the IP address ranges for Amazon DynamoDB endpoints.
    - Provisioned throughput:
    - RCU (Read Capcity Unit): 1RCU = 1 strongly consistent read / 2 eventually cosistent read of 4 KB per second
    (if you have 10 RCUs u can do 10 strongly consistent reads per sec)
    - cost $0.00012 per RCU
    - WCU (Write Capacity Unit) = 1 write 1 KB per sec (cost - 5 times RCU)
    - Option to set auto-scaling of throughtput to meet demand
    - Throughput can be exceeded temporarily using "burst credit"
    - If burst credit are empty, you'll get a provisionedThroughputException
    - DAX - DynomoDB Accelator

    A DynamoDB Accelerator (DAX) cluster is a cache that fronts your DynamoDB tables and caches
    the most frequently read values. They help offload the heavy reads on hot keys off of DynamoDB itself,
    hence preventing the ProvisionedThroughputExceededException
    ----------------
    - Seamless cache for DynamoDB, no application re-write. Micro secxonds latency for cached reads. Solves Hot
    key isssues. TTL for cache = 5 min default. Up 10 nodes in cluster. Multi AZ (3 nodes minimum)
    Dynamo DB Streams
    -----------------
    - Useful if u want cross region replication using streams
   New Features:
   - Transactions: all or nothing typres of operations. Coordinated Insert, Update & Delete across multiple tables
   -  On Demand (more expensive that provisioned. Spikes use cases, very low throughput)
   - Read more - Global Tables (Cross region replication. Active Active. Must enable Streams).
   Streams enable DynamoDB to get a changelog and use that changelog to replicate data across regions
    - Point in time restore
   - DMS can be used to migrate to DynamorDB
==================
API Gateway:
- sig v4
- Edge Optimized (default) | Regional | Private
- authn : IAM | Custom Authorizer | Cognito User Pool (Facebook, google etc - no authz)
---
AWS cognito: (see slides)
  - Cognito User Pool (CUP) | Federated Identity Pool - FIP (OpenID, STS etc) | AWS Cognito Sync (deprecated)  Use AppSync instead - uses FIP
AWS SAM (Serverless Application Model | YAML based) - logo squirrel
===
Microservice:
 Synch pattern: API Gateway, Load Balancer
 Async pattern: SQS, Kinesis, SNS, Lambda Triggers (s3)
 ==
Redshift = based on PostgreSQL. Not for OLTP but for OLAP (analytics)
         = columnar (instead of rows like conventional postgres)
         = Massively Parallel Query Execution. Pay for what is prpvisioned
         = Integrates with BI tools like AWS quickshight, tableau etc
         = upto 128 nodes upto 160 GB of space per node
Redhift Spectrum: perform queries directly against S3 ( but unlike athena not serverless)

Snapshots = point i  time backup of the cluster. Stored in S3. Incremental.
===============
Neptune - graph database. social n/w | wikipedia
ElasticSearch (Kibana - visulaization & logstash for log ingestion)
===
Important note for EC2 metrics: CloudWatch does not collect memory utilization and disk space usage metrics right from the get go.
You need to install CloudWatch Agent in your instances first to retrieve these metrics.
Test 2 - Marek q18
==
Kinesis Data Stream - Batch:
===
Use batch messages
=====

Amazon Kinesis Data Streams (KDS) is a massively scalable and durable real-time data streaming service.
KDS can continuously capture gigabytes of data per second from hundreds of thousands of sources such as website clickstreams, database event streams,
financial transactions, social media feeds, IT logs, and location-tracking events.
The data collected is available in milliseconds to enable real-time analytics use cases such as real-time dashboards, real-time anomaly detection, dynamic pricing, and more.

Kinesis Data Streams Overview:  via - https://aws.amazon.com/kinesis/data-streams/

When a host needs to send many records per second (RPS) to Amazon Kinesis,
simply calling the basic PutRecord API action in a loop is inadequate. To reduce overhead and increase throughput,
the application must batch records and implement parallel HTTP requests.
This will increase the efficiency overall and ensure you are optimally using the shards.

By default, the 2MB/second/shard output is shared between all of the applications consuming data from the stream.
You should use enhanced fan-out if you have multiple consumers retrieving data from a stream in parallel.
With enhanced fan-out developers can register stream consumers to use enhanced fan-out and receive their own 2MB/second pipe of read throughput per shard,
and this throughput automatically scales with the number of shards in a stream.
=
By default, all DynamoDB tables are encrypted under an AWS owned customer master key (CMK), which do not write to CloudTrail logs -
AWS owned CMKs are a collection of CMKs that an AWS service owns and manages for use in multiple AWS accounts.
Although AWS owned CMKs are not in your AWS account, an AWS service can use its AWS owned CMKs to protect the resources in your account.

You do not need to create or manage the AWS owned CMKs. However, you cannot view, use, track, or audit them. You are not charged a monthly fee or
usage fee for AWS owned CMKs and they do not count against the AWS KMS quotas for your account. The key rotation strategy for an AWS owned CMK is
determined by the AWS service that creates and manages the CMK. All DynamoDB tables are encrypted. There is no option to enable or disable encryption
for new or existing tables.
By default, all tables are encrypted under an AWS owned customer master key (CMK) in the DynamoDB service account.
However, you can select an option to encrypt some or all of your tables under a customer-managed CMK or the AWS managed CMK for DynamoDB in your account.
==